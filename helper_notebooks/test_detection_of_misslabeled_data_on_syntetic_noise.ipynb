{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test detection of corrupted labels based on synthetic noise\n",
    "Compare methods:\n",
    "* Use voting-based method from paper [Detecting Corrupted Labels Without Training a Model to Predict](https://proceedings.mlr.press/v162/zhu22a.html) on STT 2 dataset using BERT embeddings.\n",
    "* ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "parent_dir = Path(\"..\").absolute()\n",
    "code_dir = str(parent_dir / \"src\")\n",
    "if code_dir not in sys.path:\n",
    "    sys.path.append(code_dir)\n",
    "from master_thesis.datasets import load_ste_dataset\n",
    "from master_thesis.detection import detect_noisy_labels_based_on_local_votes\n",
    "from master_thesis.noise_generation import add_instance_dependent_noise, add_symmetric_noise\n",
    "from master_thesis.metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/home/cicheck/Downloads/stanfordSentimentTreebank/stanfordSentimentTreebank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = load_ste_dataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = len(train_df[\"sentiment\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_TO_IDX_MAP = {\n",
    "        sentiment: idx\n",
    "        for idx, sentiment in enumerate(test_df[\"sentiment\"].unique())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116    0\n",
       "1117    1\n",
       "Name: true_label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"true_label\"] = train_df[\"sentiment\"].map(\n",
    "    CLASS_TO_IDX_MAP\n",
    ")\n",
    "val_df[\"true_label\"] = val_df[\"sentiment\"].map(\n",
    "    CLASS_TO_IDX_MAP\n",
    ")\n",
    "test_df[\"true_label\"] = test_df[\"sentiment\"].map(\n",
    "    CLASS_TO_IDX_MAP\n",
    ")\n",
    "test_df[\"true_label\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "PRETRAINED_MODEL = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUMBER_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(texts: list[str], model: BertForSequenceClassification) -> list[float]:\n",
    "    \"\"\"Get text embeddings obtained from last BERT layer averaged via mean.\n",
    "    \n",
    "    Args:\n",
    "        texts: Series of texts.progress_apply\n",
    "    Returns:\n",
    "        List of embedding vectors.\n",
    "    \n",
    "    \"\"\"\n",
    "    tokenized_input = TOKENIZER(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        # We want to extract BERT embeddings!\n",
    "        outputs = model.bert(**tokenized_input)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "    # alternative approach\n",
    "    # embeddings = last_hidden_state[:, 0, :]\n",
    "    embeddings = last_hidden_state.mean(dim=1)\n",
    "    return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"embedding\"] = get_bert_embedding(train_df[\"text\"].tolist(), PRETRAINED_MODEL)\n",
    "val_df[\"embedding\"] = get_bert_embedding(val_df[\"text\"].tolist(), PRETRAINED_MODEL)\n",
    "test_df[\"embedding\"] = get_bert_embedding(test_df[\"text\"].tolist(), PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cicheck/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da72a1fd20fe43c5a8bd34417744ee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot pin 'torch.cuda.LongTensor' only dense CPU tensors can be pinned",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 100\u001b[0m\n\u001b[1;32m     79\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     80\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./results\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     logging_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m trainer \u001b[39m=\u001b[39m ClassWeightedTrainer(\n\u001b[1;32m     92\u001b[0m     class_weights\u001b[39m=\u001b[39mclass_weights,\n\u001b[1;32m     93\u001b[0m     model\u001b[39m=\u001b[39mPRETRAINED_MODEL,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     98\u001b[0m )\n\u001b[0;32m--> 100\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    101\u001b[0m \u001b[39m# Load the best model from training\u001b[39;00m\n\u001b[1;32m    102\u001b[0m trainer\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1663\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1664\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1665\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1666\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1667\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/transformers/trainer.py:1899\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1896\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1899\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1900\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1901\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:723\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m--> 723\u001b[0m     data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39;49mpin_memory\u001b[39m.\u001b[39;49mpin_memory(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pin_memory_device)\n\u001b[1;32m    724\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:55\u001b[0m, in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m     54\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)({k: pin_memory(sample, device) \u001b[39mfor\u001b[39;00m k, sample \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()})  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: pin_memory(sample, device) \u001b[39mfor\u001b[39;00m k, sample \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:55\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m     54\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)({k: pin_memory(sample, device) \u001b[39mfor\u001b[39;00m k, sample \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()})  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: pin_memory(sample, device) \u001b[39mfor\u001b[39;00m k, sample \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/master-thesis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:50\u001b[0m, in \u001b[0;36mpin_memory\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpin_memory\u001b[39m(data, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mpin_memory(device)\n\u001b[1;32m     51\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, string_classes):\n\u001b[1;32m     52\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot pin 'torch.cuda.LongTensor' only dense CPU tensors can be pinned"
     ]
    }
   ],
   "source": [
    "def compute_training_metrics(predictions):\n",
    "    logits, labels = predictions\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        # By default first metric is used during loading checkpoint\n",
    "        \"f1\": f1_score(labels, predictions, average=\"macro\"),\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"precision\": precision_score(labels, predictions, average=\"macro\"),\n",
    "        \"recall\": recall_score(labels, predictions, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_learning_curve(train_history, eval_history):\n",
    "    _, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axs[0].plot(train_history[\"f1\"], label=\"F1\")\n",
    "    axs[0].plot(train_history[\"precision\"], label=\"Precision\")\n",
    "    axs[0].plot(train_history[\"recall\"], label=\"Recall\")\n",
    "    axs[0].set_title(\"Train\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Score\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(eval_history[\"f1\"], label=\"F1\")\n",
    "    axs[1].plot(eval_history[\"precision\"], label=\"Precision\")\n",
    "    axs[1].plot(eval_history[\"recall\"], label=\"Recall\")\n",
    "    axs[1].set_title(\"Eval\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Score\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_encodings = TOKENIZER(train_df[\"text\"].tolist(), padding=True, truncation=True)\n",
    "eval_encodings = TOKENIZER(val_df[\"text\"].tolist(), padding=True, truncation=True)\n",
    "\n",
    "\n",
    "class TextClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]).to(DEVICE) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx]).to(DEVICE)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_encodings, train_df[\"true_label\"].tolist())\n",
    "eval_dataset = TextClassificationDataset(eval_encodings, val_df[\"true_label\"].tolist())\n",
    "\n",
    "\n",
    "# Compute class weights and define loss function\n",
    "class_counts = np.bincount(train_df[\"true_label\"])\n",
    "total_count = len(train_df[\"true_label\"])\n",
    "class_weights = total_count / class_counts\n",
    "\n",
    "\n",
    "class ClassWeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._class_weights = torch.tensor(class_weights).to(DEVICE)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=self._class_weights)\n",
    "        loss = loss_fct(logits.view(-1, NUMBER_OF_CLASSES), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = ClassWeightedTrainer(\n",
    "    class_weights=class_weights,\n",
    "    model=PRETRAINED_MODEL,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# Load the best model from training\n",
    "trainer.evaluate()\n",
    "train_history = {\n",
    "    key: [x[key] for x in trainer.state.log_history if \"train\" in x]\n",
    "    for key in [\"f1\", \"precision\", \"recall\"]\n",
    "}\n",
    "eval_history = {\n",
    "    key: [x[key] for x in trainer.state.log_history if \"eval\" in x]\n",
    "    for key in [\"f1\", \"precision\", \"recall\"]\n",
    "}\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(train_history, eval_history)\n",
    "model_path = trainer.state.best_model_checkpoint\n",
    "FINETUNED_MODEL = BertForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"finetuned_embedding\"] = get_bert_embedding(train_df[\"text\"].tolist(), FINETUNED_MODEL)\n",
    "val_df[\"finetuned_embedding\"] = get_bert_embedding(val_df[\"text\"].tolist(), FINETUNED_MODEL)\n",
    "test_df[\"finetuned_embedding\"] = get_bert_embedding(test_df[\"text\"].tolist(), FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to save time\n",
    "train_df.to_pickle(\"data/ste_train.pickle\")\n",
    "val_df.to_pickle(\"data/ste_val.pickle\")\n",
    "test_df.to_pickle(\"data/ste_test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"data/ste_train.pickle\")\n",
    "val_df = pd.read_pickle(\"data/ste_val.pickle\")\n",
    "test_df = pd.read_pickle(\"data/ste_test.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_rates_space = [\n",
    "    0.0,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.3,\n",
    "    0.4,\n",
    "    0.5,\n",
    "    0.6,\n",
    "    0.7,\n",
    "    0.8,\n",
    "    0.9,\n",
    "    1.0,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS = torch.tensor(test_df[\"embedding\"].tolist())\n",
    "FINETUNED_EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_noise_metrics = []\n",
    "\n",
    "for corruption_rate in corruption_rates_space:\n",
    "    true_labels = test_df[\"true_label\"].tolist()\n",
    "    noisy_labels = add_symmetric_noise(\n",
    "        true_labels=true_labels,\n",
    "        corruption_rate=corruption_rate,\n",
    "    )\n",
    "    ground_truth = [\n",
    "        true_label != noisy_label for true_label, noisy_label in zip(true_labels, noisy_labels)\n",
    "    ]\n",
    "    detected_corruptions = detect_noisy_labels_based_on_local_votes(\n",
    "        features=FEATURES,\n",
    "        original_labels=torch.tensor(true_labels),\n",
    "    )\n",
    "    symmetric_noise_metrics.append(\n",
    "        {\n",
    "            \"Noise Type\": \"Symmetric\",\n",
    "            \"Noise Rate\": corruption_rate,\n",
    "            \"Detection Method\": \"SimFeat-V\",\n",
    "            **compute_metrics(ground_truth=ground_truth, predictions=detected_corruptions),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetric noise\n",
    "Sentiment can only shift for 1, e.g. `VERY_NEGATIVE` can only transition into `NEGATIVE` and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_TRANSITION_MAP = {\n",
    "    \"VERY_NEGATIVE\": [\"NEGATIVE\"],\n",
    "    \"NEGATIVE\": [\"VERY_NEGATIVE\", \"NEUTRAL\"],\n",
    "    \"NEUTRAL\": [\"NEGATIVE\", \"POSITIVE\"],\n",
    "    \"POSITIVE\": [\"NEUTRAL\", \"VERY_POSITIVE\"],\n",
    "    \"VERY_POSITIVE\": [\"POSITIVE\"],\n",
    "}\n",
    "SENTIMENT_TRANSITION_MAP = {\n",
    "    CLASS_TO_IDX_MAP[sentiment]: [\n",
    "        CLASS_TO_IDX_MAP[transition_sentiment] for transition_sentiment in transition_sentiments\n",
    "    ]\n",
    "    for sentiment, transition_sentiments in SENTIMENT_TRANSITION_MAP.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
